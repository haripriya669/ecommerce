Step 1: Install Required Libraries
Ensure you have the necessary Python libraries installed:


pip install pandas numpy scikit-learn surprise
Step 2: Import Libraries

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from surprise import Dataset, Reader, SVD
from surprise.model_selection import cross_validate
from surprise import accuracy
from surprise.model_selection import train_test_split as surprise_train_test_split
from surprise import KNNWithMeans
from collections import defaultdict
Step 3: Load and Prepare Data
For this example, we will use a simple dataset that includes user IDs, product IDs, and ratings (implicit feedback like clicks or explicit feedback like star ratings). You can replace this with your own data.


# Sample data: user_id, product_id, rating
data = {'user_id': [1, 1, 1, 2, 2, 3, 3, 3, 4, 4],
        'product_id': [101, 102, 103, 101, 104, 102, 103, 105, 101, 105],
        'rating': [5, 3, 4, 2, 5, 5, 4, 3, 3, 4]}

df = pd.DataFrame(data)
print(df.head())
Step 4: Data Preprocessing
Convert the data into a format suitable for the Surprise library, which is specialized for building recommendation systems.


# Load data into Surprise format
reader = Reader(rating_scale=(1, 5))
data = Dataset.load_from_df(df[['user_id', 'product_id', 'rating']], reader)
Step 5: Build Collaborative Filtering Model
We'll use the Singular Value Decomposition (SVD) algorithm, which is a popular collaborative filtering method for recommendation systems.


# Split the data into training and testing sets
trainset, testset = surprise_train_test_split(data, test_size=0.2)

# Use the SVD algorithm
algo = SVD()

# Train the algorithm on the trainset
algo.fit(trainset)

# Test the algorithm on the testset
predictions = algo.test(testset)

# Evaluate the model
accuracy.rmse(predictions)
Step 6: Generate Recommendations
We can generate personalized recommendations for a specific user by predicting ratings for all products the user has not interacted with yet.


# Function to get top-N recommendations for each user
def get_top_n(predictions, n=10):
    # Map the predictions to each user.
    top_n = defaultdict(list)
    for uid, iid, true_r, est, _ in predictions:
        top_n[uid].append((iid, est))

    # Sort the predictions for each user and retrieve the top-N items.
    for uid, user_ratings in top_n.items():
        user_ratings.sort(key=lambda x: x[1], reverse=True)
        top_n[uid] = user_ratings[:n]

    return top_n

# Generate predictions for all pairs (user, product) that are not in the training set
testset_all = trainset.build_anti_testset()
predictions = algo.test(testset_all)

# Get top 5 recommendations for each user
top_n_recommendations = get_top_n(predictions, n=5)

# Display recommendations for each user
for user_id, recommendations in top_n_recommendations.items():
    print(f"User {user_id}:")
    for product_id, estimated_rating in recommendations:
        print(f"  Product {product_id}: Estimated Rating {estimated_rating:.2f}")
Step 7: Item-Based Collaborative Filtering (Optional)
For an item-based approach, you can use KNN (K-Nearest Neighbors) with mean to recommend products similar to what the user has liked in the past.


# Use KNNWithMeans for item-based collaborative filtering
algo_knn = KNNWithMeans(k=10, sim_options={'name': 'pearson_baseline', 'user_based': False})
algo_knn.fit(trainset)

# Test the algorithm
predictions_knn = algo_knn.test(testset)

# Evaluate the model
accuracy.rmse(predictions_knn)

Conclusion:
This project covers the essentials of building an e-commerce product recommendation system using collaborative filtering methods like SVD and KNN. You can further improve this system by incorporating more advanced algorithms, such as matrix factorization, content-based filtering, or hybrid models combining multiple techniques.
